{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Prediction Problem Final Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b9670",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. This is the template for the code and final report on the Prediction Problem.\n",
    "\n",
    "2. You may modify the template if you see fit, but it should have the information asked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9423686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data Preprocessing\n",
    "\n",
    "Steps for cleaning and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b494b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"train_X.csv\")\n",
    "train_y = pd.read_csv(\"train_y.csv\")\n",
    "test = pd.read_csv('public_private_X.csv')\n",
    "train = train_X.merge(train_y, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73dadf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_predictors = train_X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa1a29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_remove = ['PRODUCT_MARKET', 'ID', 'PRODUCT_STATUS', 'PURCHASE_ORDER_DUE_DATE', 'ORDER_DATE', 'DIVISION_CODE', 'RESERVABLE_INDICATOR']\n",
    "for value in values_to_remove:\n",
    "    relevant_predictors.remove(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819bbbf",
   "metadata": {},
   "source": [
    "1. PRODUCT_MARKET: This was just the addition of PRODUCT_NUMBER and DIVISION_NUMBER so I thought it was repetitive.\n",
    "\n",
    "2. ID: This is a unique value for each observation so this would not help the logistic regression.\n",
    "\n",
    "3. PRODUCT_STATUS, RESERVABLE_INDICATOR: Both of them only have one unique value so they are not good predictors.\n",
    "\n",
    "4. PURCHASE_ORDER_DUE_DATE, ORDER_DATE: There are other predictors that are related to dates that are more useful and numerical. In addition, the date range is very different between the train and test data so they won't be useful predictors.\n",
    "\n",
    "5. DIVISION_CODE: This is the same variable as DIVISION_NUMBER so it is repetitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used KNN imputation for imputing missing values\n",
    "columns_to_impute = ['AVERAGE_DAILY_DEMAND_CASES', 'AVERAGE_VENDOR_ORDER_CYCLE_DAYS', \n",
    "                     'AVERAGE_ORDER_CYCLE_DAYS', 'AVERAGE_ORDER_CYCLE_CASES']\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Impute for train data\n",
    "train_imputed = knn_imputer.fit_transform(train[columns_to_impute])\n",
    "train[columns_to_impute] = pd.DataFrame(train_imputed, columns=columns_to_impute)\n",
    "\n",
    "# Impute for test data\n",
    "test_imputed = knn_imputer.transform(test[columns_to_impute])\n",
    "test[columns_to_impute] = pd.DataFrame(test_imputed, columns=columns_to_impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Feature Engineering\n",
    "\n",
    "Techniques used to create meaningful features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19bf05",
   "metadata": {},
   "source": [
    "### 2-1. Log transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2868d7",
   "metadata": {},
   "source": [
    "Applied log transformation to numerical predictors that were highly right skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4fba290",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'DISTANCE_IN_MILES', \n",
    "    'AVERAGE_PRODUCT_ORDER_QUANTITY_MARKET', \n",
    "    'ORDER_QUANTITY_DEVIATION', \n",
    "    'GIVEN_TIME_TO_LEAD_TIME_RATIO', \n",
    "    'AVERAGE_DAILY_DEMAND_CASES', \n",
    "    'AVERAGE_VENDOR_ORDER_CYCLE_DAYS', \n",
    "    'AVERAGE_ORDER_CYCLE_DAYS', \n",
    "    'AVERAGE_ORDER_CYCLE_CASES', \n",
    "    'LEAD_TIME_TO_DISTANCE_RATIO'\n",
    "]\n",
    "\n",
    "# Apply log1p transformation to all specified predictors\n",
    "train[predictors] = np.log1p(train[predictors])\n",
    "test[predictors] = np.log1p(test[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b772c2",
   "metadata": {},
   "source": [
    "### 2-2. Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc49ad9",
   "metadata": {},
   "source": [
    "For numerical variables that had a cluster of extreme outliers, I binned them so they do not impact the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b93213",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_vars = [\n",
    "    'TRANSIT_LEAD_TIME', \n",
    "    'PURCHASING_LEAD_TIME', \n",
    "    'DAYS_BETWEEN_ORDER_AND_DUE_DATE'\n",
    "]\n",
    "\n",
    "for var in bin_vars:\n",
    "    train[f'{var}_BINNED'] = pd.qcut(train[var], q=8, labels=False, duplicates='drop')\n",
    "    test[f'{var}_BINNED'] = pd.qcut(test[var], q=8, labels=False, duplicates='drop')\n",
    "\n",
    "for var in bin_vars:\n",
    "    relevant_predictors.remove(var)\n",
    "    relevant_predictors.append(f'{var}_BINNED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5c72e",
   "metadata": {},
   "source": [
    "### 2-3. Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb5b38",
   "metadata": {},
   "source": [
    "1. DIVISION_NUMBER\n",
    "\n",
    "I've noticed that division number 102 and 100 hvae similar completion rates and assumed they behaved similarly. Therefore, I grouped them to reduce model complexity. The calculations are in the Interim Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdda433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DIVISION_NUMBER'] = train['DIVISION_NUMBER'].replace(102, 100)\n",
    "test['DIVISION_NUMBER'] = test['DIVISION_NUMBER'].replace(102, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0fbcbc",
   "metadata": {},
   "source": [
    "2. ORDER_DAY_OF_WEEK \n",
    "\n",
    "I removed this variable since each day of the week had similar completion rates. I assumed it won't be helpful for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1badd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_predictors.remove(\"ORDER_DAY_OF_WEEK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63c617",
   "metadata": {},
   "source": [
    "3. DUE_DATE_WEEKDAY\n",
    "\n",
    "I've noticed that this variable had two main groups where one group had a high completion rate and the other with a lower completion rate. I divided them accordingly to reduce model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "167251f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_day(day):\n",
    "    if day in [1, 2, 4, 6]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "train['DUE_DATE_WEEKDAY_CATEGORY'] = train['DUE_DATE_WEEKDAY'].apply(categorize_day)\n",
    "test['DUE_DATE_WEEKDAY_CATEGORY'] = test['DUE_DATE_WEEKDAY'].apply(categorize_day)\n",
    "\n",
    "relevant_predictors.remove(\"DUE_DATE_WEEKDAY\")\n",
    "relevant_predictors.append('DUE_DATE_WEEKDAY_CATEGORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccaf8d",
   "metadata": {},
   "source": [
    "4. PURCHASE_ORDER_TYPE - Kept as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7fdf9",
   "metadata": {},
   "source": [
    "5. PRODUCT_CLASSIFICATION & PRODUCT_NUMBER\n",
    "\n",
    "Both variables had high cardinality, but had varying completion rates for each group. However, due to the high number of unique values, I chose to do target encoding where each variable was replaced with their group's mean completion rate. I filtered out groups with less than 10 occurrences so they do not skew the distribution and imputed them with the global completion mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a2f322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Classification\n",
    "product_counts = train['PRODUCT_CLASSIFICATION'].value_counts()\n",
    "\n",
    "global_mean = train['ON_TIME_AND_COMPLETE'].mean()\n",
    "\n",
    "product_group_means = train.groupby('PRODUCT_CLASSIFICATION')['ON_TIME_AND_COMPLETE'].mean()\n",
    "\n",
    "train['PRODUCT_CLASSIFICATION_encoded'] = train['PRODUCT_CLASSIFICATION'].map(\n",
    "    lambda x: product_group_means[x] if product_counts[x] >= 10 else global_mean\n",
    ")\n",
    "\n",
    "test['PRODUCT_CLASSIFICATION_encoded'] = test['PRODUCT_CLASSIFICATION'].map(\n",
    "    lambda x: product_group_means.get(x, global_mean) if x in product_group_means else global_mean\n",
    ")\n",
    "\n",
    "# Product Number\n",
    "product_counts = train['PRODUCT_NUMBER'].value_counts()\n",
    "\n",
    "product_group_means = train.groupby('PRODUCT_NUMBER')['ON_TIME_AND_COMPLETE'].mean()\n",
    "\n",
    "train['PRODUCT_NUMBER_encoded'] = train['PRODUCT_NUMBER'].map(\n",
    "    lambda x: product_group_means[x] if product_counts[x] >= 10 else global_mean\n",
    ")\n",
    "\n",
    "test['PRODUCT_NUMBER_encoded'] = test['PRODUCT_NUMBER'].map(\n",
    "    lambda x: product_group_means.get(x, global_mean) if x in product_group_means else global_mean\n",
    ")\n",
    "\n",
    "relevant_predictors.remove(\"PRODUCT_CLASSIFICATION\")\n",
    "relevant_predictors.append('PRODUCT_CLASSIFICATION_encoded')\n",
    "relevant_predictors.remove(\"PRODUCT_NUMBER\")\n",
    "relevant_predictors.append('PRODUCT_NUMBER_encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4cb17e",
   "metadata": {},
   "source": [
    "6. COMPANY_VENDOR_NUMBER & PURCHASE_FROM_VENDOR\n",
    "\n",
    "Similarly, both variables had high cardinality, but varying completion rates, which is a good sign as a predictor. For similar reasons, I implemented target encoding, but in a slightly different manner. Since most of the groups had a reasonable amount of occurrences, I imputed with the average of the completion rate for each group and a smoothing factor so lower frequency groups do not skew the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b08095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20\n",
    "\n",
    "# Calculate category mean and global mean\n",
    "category_mean = train.groupby('COMPANY_VENDOR_NUMBER')['ON_TIME_AND_COMPLETE'].mean()\n",
    "global_mean = train['ON_TIME_AND_COMPLETE'].mean()\n",
    "category_size = train['COMPANY_VENDOR_NUMBER'].value_counts()\n",
    "\n",
    "train['COMPANY_VENDOR_NUMBER_ENCODED'] = train['COMPANY_VENDOR_NUMBER'].map(\n",
    "    lambda x: ((category_mean.get(x, global_mean) * category_size.get(x, 0)) + (global_mean * m)) / \n",
    "              (category_size.get(x, 0) + m)\n",
    ")\n",
    "\n",
    "# Compute target encoding for test set and fill missing categories with global mean\n",
    "test['COMPANY_VENDOR_NUMBER_ENCODED'] = test['COMPANY_VENDOR_NUMBER'].map(\n",
    "    lambda x: ((category_mean.get(x, global_mean) * category_size.get(x, 0)) + (global_mean * m)) / \n",
    "              (category_size.get(x, 0) + m)\n",
    ").fillna(global_mean)\n",
    "\n",
    "# Calculate category mean and global mean\n",
    "category_mean = train.groupby('PURCHASE_FROM_VENDOR')['ON_TIME_AND_COMPLETE'].mean()\n",
    "global_mean = train['ON_TIME_AND_COMPLETE'].mean()\n",
    "category_size = train['PURCHASE_FROM_VENDOR'].value_counts()\n",
    "\n",
    "# Compute target encoding\n",
    "train['PURCHASE_FROM_VENDOR_ENCODED'] = train['PURCHASE_FROM_VENDOR'].map(\n",
    "    lambda x: ((category_mean.get(x, global_mean) * category_size.get(x, 0)) + (global_mean * m)) / \n",
    "              (category_size.get(x, 0) + m)\n",
    ")\n",
    "\n",
    "# Compute target encoding for test set and fill missing categories with global mean\n",
    "test['PURCHASE_FROM_VENDOR_ENCODED'] = test['PURCHASE_FROM_VENDOR'].map(\n",
    "    lambda x: ((category_mean.get(x, global_mean) * category_size.get(x, 0)) + (global_mean * m)) / \n",
    "              (category_size.get(x, 0) + m)\n",
    ").fillna(global_mean)\n",
    "\n",
    "relevant_predictors.remove(\"COMPANY_VENDOR_NUMBER\")\n",
    "relevant_predictors.append('COMPANY_VENDOR_NUMBER_ENCODED')\n",
    "relevant_predictors.remove(\"PURCHASE_FROM_VENDOR\")\n",
    "relevant_predictors.append('PURCHASE_FROM_VENDOR_ENCODED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12577d04",
   "metadata": {},
   "source": [
    "7. SHIP_FROM_VENDOR\n",
    "\n",
    "This was one of the most highly correlated categorical variables but target encoding would always remove this variable during lasso. Therefore, I binned into three groups according to the mean completion rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1532973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will divide the predictor into three groups using qcut\n",
    "mean_div = train.groupby('SHIP_FROM_VENDOR', observed=False)['ON_TIME_AND_COMPLETE'].mean().reset_index()\n",
    "\n",
    "mean_div['SHIP_FROM_VENDOR_GROUP'] = pd.qcut(mean_div['ON_TIME_AND_COMPLETE'], \n",
    "                                             q=[0, 0.3, 0.7, 1.0], \n",
    "                                             labels=['Low', 'Middle', 'High'], \n",
    "                                             duplicates='drop')\n",
    "\n",
    "train = train.merge(mean_div[['SHIP_FROM_VENDOR', 'SHIP_FROM_VENDOR_GROUP']], on='SHIP_FROM_VENDOR', how='left')\n",
    "\n",
    "test = test.merge(mean_div[['SHIP_FROM_VENDOR', 'SHIP_FROM_VENDOR_GROUP']], on='SHIP_FROM_VENDOR', how='left')\n",
    "\n",
    "default_group = mean_div['SHIP_FROM_VENDOR_GROUP'].mode()[0]\n",
    "\n",
    "# Assign the mode to NaN values in the test set\n",
    "test['SHIP_FROM_VENDOR_GROUP'] = test['SHIP_FROM_VENDOR_GROUP'].fillna(default_group)\n",
    "\n",
    "relevant_predictors.remove(\"SHIP_FROM_VENDOR\")\n",
    "relevant_predictors.append('SHIP_FROM_VENDOR_GROUP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9268d",
   "metadata": {},
   "source": [
    "*All EDA and rationals for bin edges and grouping are in the Interim Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a03db",
   "metadata": {},
   "source": [
    "## 3) Developing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ef068",
   "metadata": {},
   "source": [
    "I created dummies for all categorical variables with the exception of SHIP_FROM_VENDOR_GROUP that had a strict ordinal order. Therefore, ordinal encoding was applied. For polynomial transformation, I assumed some numerical variables had a more complex relationship with the target, more than a linear relationship. Therefore, I chose degree=3 with the addition of interaction terms. I finally scaled everything at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "410980ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = train[relevant_predictors].select_dtypes(include='int').columns.tolist()\n",
    "float_var = train[relevant_predictors].select_dtypes(include='float64').columns.tolist()\n",
    "\n",
    "X_train = train[relevant_predictors].copy()\n",
    "y_train = train_y['ON_TIME_AND_COMPLETE']\n",
    "X_test = test[relevant_predictors].copy()\n",
    "\n",
    "# 1. One-Hot Encode cat_var\n",
    "X_train_onehot = pd.get_dummies(train[cat_var], columns=cat_var).astype(int)\n",
    "X_test_onehot = pd.get_dummies(test[cat_var], columns=cat_var).astype(int)\n",
    "\n",
    "# 2. Ordinal Encoding for SHIP_FROM_VENDOR_GROUP\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform training data\n",
    "train['SHIP_FROM_VENDOR_GROUP'] = encoder.fit_transform(train[['SHIP_FROM_VENDOR_GROUP']])\n",
    "train_encoded = pd.DataFrame(train['SHIP_FROM_VENDOR_GROUP'], columns=['SHIP_FROM_VENDOR_GROUP'])\n",
    "\n",
    "# Transform test data\n",
    "test['SHIP_FROM_VENDOR_GROUP'] = encoder.fit_transform(test[['SHIP_FROM_VENDOR_GROUP']])\n",
    "test_encoded = pd.DataFrame(test['SHIP_FROM_VENDOR_GROUP'], columns=['SHIP_FROM_VENDOR_GROUP'])\n",
    "\n",
    "# 3. Create interaction terms for float_var using PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "X_train_num = pd.DataFrame(poly.fit_transform(train[float_var]), columns=poly.get_feature_names_out(train[float_var].columns))\n",
    "X_test_num = pd.DataFrame(poly.transform(test[float_var]), columns=poly.get_feature_names_out(train[float_var].columns))\n",
    "\n",
    "# Combine both the one-hot encoded and polynomial features\n",
    "X_train_combined = pd.concat([X_train_onehot, X_train_num, train_encoded], axis=1)\n",
    "X_test_combined = pd.concat([X_test_onehot, X_test_num, test_encoded], axis=1)\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_final = pd.DataFrame(scaler.fit_transform(X_train_combined), columns=X_train_combined.columns)\n",
    "X_test_final = pd.DataFrame(scaler.transform(X_test_combined), columns=X_test_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 4) Model Fine Tuning\n",
    "\n",
    "Including cross-validation, regularization, and hyperparameter tuning, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261c919",
   "metadata": {},
   "source": [
    "I used Lasso to remove any irrelevant predictors and liblinear turned out to have a better overall accuracy score. The range of C values was chosen by guess and check where I learned that c values that were greater than 1 was too weak of a regularization (did not remove a lot of predictors). To reduce running time, I used RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2896793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best C value: 0.6951927961775606\n",
      "Best score: 0.7843530188087627\n"
     ]
    }
   ],
   "source": [
    "# Define the Lasso model\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=3000, random_state=42)\n",
    "\n",
    "# Define the parameter grid with a range of C values\n",
    "param_dist = {'C': np.logspace(-3, 0, 20)}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    cv=5,     \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV on the data\n",
    "random_search.fit(X_train_final, y_train)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best C value: {random_search.best_params_['C']}\")\n",
    "print(f\"Best score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c862db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "y_pred = random_search.predict(X_test_final)\n",
    "\n",
    "# Save Predictions\n",
    "test_ids = test['ID']\n",
    "predictions_df = pd.DataFrame({'ID': test_ids, 'ON_TIME_AND_COMPLETE': y_pred})\n",
    "predictions_df.to_csv('final_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cfebad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5165)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['ON_TIME_AND_COMPLETE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf866d",
   "metadata": {},
   "source": [
    "Please note that your code should be reproducible, well-structured, and include clear comments for readability.\n",
    "Your code should generate the csv file that you submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193ff8e",
   "metadata": {},
   "source": [
    "This generated an accuracy of 76.4% with the public test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eccea2",
   "metadata": {},
   "source": [
    "## 5) Key Takeaways (Short Reflection)\n",
    "\n",
    "* Provide a brief summary of your key takeaways from this prediction problem.\n",
    "* Reflect on challenges faced and lessons learned from your model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978d837",
   "metadata": {},
   "source": [
    "The prediction problem was a very challenging yet fun project. I think the biggest takeaway I got was that data science and machine learning has no exact answers. I was surprised at how differently students approached this prediction problem and how many variations can happen within a single method. Unlike tests that have an exact answer, this problem only had a target threshold and we were allowed to use any methods or functions that we learned to achieve that in any way. This journey of finding my own unique path for the target threshold was difficult, but very rewarding. Another takeaway was that modeling is a very sensitive and keen process. Slight tweaks and a change in the tenth decimal place would fluctuate the accuracy scores a lot or an inclusion or exclusion of a variable signficantly affect the model performance.\n",
    "\n",
    "This very reason made the model building process difficult for me. Since each model is so sensitive to the approach and even to a decimal point in a binning process, there was no clear answer or solution to make my model better. Although there are recommended steps to take, it turns out that some do not work for your model. This process was very frustrating since some proposed methods significantly made other students' models better, but not for mine. However, I learned that just keep trying new methods and new tweaks will eventually make the the model better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASSIGNMENTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
